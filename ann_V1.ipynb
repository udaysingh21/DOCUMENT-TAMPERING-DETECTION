{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split # split data into train and test sets\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential # ANN architecture\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten # ANN layers\n",
    "from tensorflow.keras.activations import relu, sigmoid # activation functions\n",
    "from tensorflow.keras.optimizers import SGD, Adam # optimizers\n",
    "from tensorflow.keras.losses import binary_crossentropy # loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mse</th>\n",
       "      <th>mse_lab</th>\n",
       "      <th>mse_magnitude</th>\n",
       "      <th>mse_phase</th>\n",
       "      <th>med_magnitude</th>\n",
       "      <th>med_phase</th>\n",
       "      <th>hvs1</th>\n",
       "      <th>hvs2</th>\n",
       "      <th>hvs3</th>\n",
       "      <th>ssim</th>\n",
       "      <th>ncc</th>\n",
       "      <th>if_value</th>\n",
       "      <th>histogram</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12609</th>\n",
       "      <td>5118</td>\n",
       "      <td>272.0</td>\n",
       "      <td>3.160146</td>\n",
       "      <td>272.899750</td>\n",
       "      <td>3.716570</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.039292</td>\n",
       "      <td>0.135823</td>\n",
       "      <td>113.483824</td>\n",
       "      <td>0.955859</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>136.927794</td>\n",
       "      <td>13.670006</td>\n",
       "      <td>Tampered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12610</th>\n",
       "      <td>5119</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.868469</td>\n",
       "      <td>146.076800</td>\n",
       "      <td>3.738477</td>\n",
       "      <td>254.0</td>\n",
       "      <td>3.988071e-04</td>\n",
       "      <td>0.039192</td>\n",
       "      <td>0.047764</td>\n",
       "      <td>124.019408</td>\n",
       "      <td>0.973298</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>73.525050</td>\n",
       "      <td>13.944947</td>\n",
       "      <td>Tampered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12611</th>\n",
       "      <td>5120</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.052999</td>\n",
       "      <td>18.178000</td>\n",
       "      <td>2.130556</td>\n",
       "      <td>255.0</td>\n",
       "      <td>2.856436e-02</td>\n",
       "      <td>0.013885</td>\n",
       "      <td>0.084138</td>\n",
       "      <td>89.379875</td>\n",
       "      <td>0.992990</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>9.585495</td>\n",
       "      <td>11.527247</td>\n",
       "      <td>Tampered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12612</th>\n",
       "      <td>5121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.582408</td>\n",
       "      <td>3.228241</td>\n",
       "      <td>1.691034</td>\n",
       "      <td>255.0</td>\n",
       "      <td>7.105427e-15</td>\n",
       "      <td>0.017413</td>\n",
       "      <td>0.010012</td>\n",
       "      <td>124.402487</td>\n",
       "      <td>0.997959</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>2.113100</td>\n",
       "      <td>12.071681</td>\n",
       "      <td>Tampered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12613</th>\n",
       "      <td>5122</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.607705</td>\n",
       "      <td>203.099950</td>\n",
       "      <td>4.224677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.065381</td>\n",
       "      <td>0.201001</td>\n",
       "      <td>112.889401</td>\n",
       "      <td>0.945832</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>102.022887</td>\n",
       "      <td>10.487417</td>\n",
       "      <td>Tampered</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0    mse   mse_lab  mse_magnitude  mse_phase  med_magnitude   \n",
       "12609        5118  272.0  3.160146     272.899750   3.716570          253.0  \\\n",
       "12610        5119  146.0  1.868469     146.076800   3.738477          254.0   \n",
       "12611        5120   18.0  1.052999      18.178000   2.130556          255.0   \n",
       "12612        5121    3.0  0.582408       3.228241   1.691034          255.0   \n",
       "12613        5122  203.0  0.607705     203.099950   4.224677            0.0   \n",
       "\n",
       "          med_phase      hvs1      hvs2        hvs3      ssim       ncc   \n",
       "12609  0.000000e+00  0.039292  0.135823  113.483824  0.955859  0.000311  \\\n",
       "12610  3.988071e-04  0.039192  0.047764  124.019408  0.973298  0.000232   \n",
       "12611  2.856436e-02  0.013885  0.084138   89.379875  0.992990  0.000310   \n",
       "12612  7.105427e-15  0.017413  0.010012  124.402487  0.997959  0.000495   \n",
       "12613  0.000000e+00  0.065381  0.201001  112.889401  0.945832  0.000205   \n",
       "\n",
       "         if_value  histogram     class  \n",
       "12609  136.927794  13.670006  Tampered  \n",
       "12610   73.525050  13.944947  Tampered  \n",
       "12611    9.585495  11.527247  Tampered  \n",
       "12612    2.113100  12.071681  Tampered  \n",
       "12613  102.022887  10.487417  Tampered  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('dataset.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mse</th>\n",
       "      <th>mse_lab</th>\n",
       "      <th>mse_magnitude</th>\n",
       "      <th>mse_phase</th>\n",
       "      <th>med_magnitude</th>\n",
       "      <th>med_phase</th>\n",
       "      <th>hvs1</th>\n",
       "      <th>hvs2</th>\n",
       "      <th>hvs3</th>\n",
       "      <th>ssim</th>\n",
       "      <th>ncc</th>\n",
       "      <th>if_value</th>\n",
       "      <th>histogram</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12609</th>\n",
       "      <td>5118</td>\n",
       "      <td>272.0</td>\n",
       "      <td>3.160146</td>\n",
       "      <td>272.899750</td>\n",
       "      <td>3.716570</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.039292</td>\n",
       "      <td>0.135823</td>\n",
       "      <td>113.483824</td>\n",
       "      <td>0.955859</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>136.927794</td>\n",
       "      <td>13.670006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12610</th>\n",
       "      <td>5119</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.868469</td>\n",
       "      <td>146.076800</td>\n",
       "      <td>3.738477</td>\n",
       "      <td>254.0</td>\n",
       "      <td>3.988071e-04</td>\n",
       "      <td>0.039192</td>\n",
       "      <td>0.047764</td>\n",
       "      <td>124.019408</td>\n",
       "      <td>0.973298</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>73.525050</td>\n",
       "      <td>13.944947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12611</th>\n",
       "      <td>5120</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.052999</td>\n",
       "      <td>18.178000</td>\n",
       "      <td>2.130556</td>\n",
       "      <td>255.0</td>\n",
       "      <td>2.856436e-02</td>\n",
       "      <td>0.013885</td>\n",
       "      <td>0.084138</td>\n",
       "      <td>89.379875</td>\n",
       "      <td>0.992990</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>9.585495</td>\n",
       "      <td>11.527247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12612</th>\n",
       "      <td>5121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.582408</td>\n",
       "      <td>3.228241</td>\n",
       "      <td>1.691034</td>\n",
       "      <td>255.0</td>\n",
       "      <td>7.105427e-15</td>\n",
       "      <td>0.017413</td>\n",
       "      <td>0.010012</td>\n",
       "      <td>124.402487</td>\n",
       "      <td>0.997959</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>2.113100</td>\n",
       "      <td>12.071681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12613</th>\n",
       "      <td>5122</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.607705</td>\n",
       "      <td>203.099950</td>\n",
       "      <td>4.224677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.065381</td>\n",
       "      <td>0.201001</td>\n",
       "      <td>112.889401</td>\n",
       "      <td>0.945832</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>102.022887</td>\n",
       "      <td>10.487417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0    mse   mse_lab  mse_magnitude  mse_phase  med_magnitude   \n",
       "12609        5118  272.0  3.160146     272.899750   3.716570          253.0  \\\n",
       "12610        5119  146.0  1.868469     146.076800   3.738477          254.0   \n",
       "12611        5120   18.0  1.052999      18.178000   2.130556          255.0   \n",
       "12612        5121    3.0  0.582408       3.228241   1.691034          255.0   \n",
       "12613        5122  203.0  0.607705     203.099950   4.224677            0.0   \n",
       "\n",
       "          med_phase      hvs1      hvs2        hvs3      ssim       ncc   \n",
       "12609  0.000000e+00  0.039292  0.135823  113.483824  0.955859  0.000311  \\\n",
       "12610  3.988071e-04  0.039192  0.047764  124.019408  0.973298  0.000232   \n",
       "12611  2.856436e-02  0.013885  0.084138   89.379875  0.992990  0.000310   \n",
       "12612  7.105427e-15  0.017413  0.010012  124.402487  0.997959  0.000495   \n",
       "12613  0.000000e+00  0.065381  0.201001  112.889401  0.945832  0.000205   \n",
       "\n",
       "         if_value  histogram  class  \n",
       "12609  136.927794  13.670006      1  \n",
       "12610   73.525050  13.944947      1  \n",
       "12611    9.585495  11.527247      1  \n",
       "12612    2.113100  12.071681      1  \n",
       "12613  102.022887  10.487417      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].replace('Original',0,inplace=True)\n",
    "df['class'].replace('Tampered',1,inplace=True)\n",
    "df.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12614 entries, 0 to 12613\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   mse            12614 non-null  float64\n",
      " 1   mse_lab        12614 non-null  float64\n",
      " 2   mse_magnitude  12614 non-null  float64\n",
      " 3   mse_phase      12614 non-null  float64\n",
      " 4   med_magnitude  12614 non-null  float64\n",
      " 5   med_phase      12614 non-null  float64\n",
      " 6   hvs1           12606 non-null  float64\n",
      " 7   hvs2           12614 non-null  float64\n",
      " 8   hvs3           12614 non-null  float64\n",
      " 9   ssim           12614 non-null  float64\n",
      " 10  ncc            12614 non-null  float64\n",
      " 11  if_value       12614 non-null  float64\n",
      " 12  histogram      12614 non-null  float64\n",
      " 13  class          12614 non-null  int64  \n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df=df.drop('Unnamed: 0',axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True) # Replace inf values with NaN\n",
    "df.dropna(inplace=True) # Drop rows with NaN values\n",
    "# X,Y are the features and target variables respectively\n",
    "X = df.drop('class',axis=1) # Drop the target variable which is a class ie Original/Tampered\n",
    "y = df['class'] # Keep the target variable in a separate variable y\n",
    "X= np.log1p(X) # Handle extremely large values by taking the log of the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12604, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # Check the shape of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating ANN Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                896       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,009\n",
      "Trainable params: 3,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the ANN Neural Network\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_shape=(13,))) # input layer\n",
    "model.add(Dense(units=32, activation='relu'))  # hidden layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # output layer\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # Compile the model\n",
    "model.summary() # Print the model summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10083, 13) (2521, 13) (10083,) (2521,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Split the data into train and test sets\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape) # Check the shape of the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "253/253 [==============================] - 7s 11ms/step - loss: 0.6786 - accuracy: 0.5891 - val_loss: 0.6721 - val_accuracy: 0.5999\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.6693 - accuracy: 0.5957 - val_loss: 0.6699 - val_accuracy: 0.5900\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 4s 18ms/step - loss: 0.6631 - accuracy: 0.5988 - val_loss: 0.6567 - val_accuracy: 0.6049\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.6516 - accuracy: 0.6084 - val_loss: 0.6425 - val_accuracy: 0.6187\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.6388 - accuracy: 0.6284 - val_loss: 0.6370 - val_accuracy: 0.6277\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.6308 - accuracy: 0.6325 - val_loss: 0.6385 - val_accuracy: 0.6138\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.6243 - accuracy: 0.6359 - val_loss: 0.6351 - val_accuracy: 0.6351\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 2s 9ms/step - loss: 0.6172 - accuracy: 0.6460 - val_loss: 0.6168 - val_accuracy: 0.6525\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 1s 6ms/step - loss: 0.6106 - accuracy: 0.6546 - val_loss: 0.6156 - val_accuracy: 0.6450\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.6037 - accuracy: 0.6663 - val_loss: 0.6110 - val_accuracy: 0.6520\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.5993 - accuracy: 0.6701 - val_loss: 0.6050 - val_accuracy: 0.6634\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5933 - accuracy: 0.6749 - val_loss: 0.6040 - val_accuracy: 0.6708\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.5866 - accuracy: 0.6814 - val_loss: 0.6052 - val_accuracy: 0.6634\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5855 - accuracy: 0.6852 - val_loss: 0.5962 - val_accuracy: 0.6822\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.5828 - accuracy: 0.6878 - val_loss: 0.5934 - val_accuracy: 0.6886\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5765 - accuracy: 0.6956 - val_loss: 0.5833 - val_accuracy: 0.7000\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.5741 - accuracy: 0.7001 - val_loss: 0.5843 - val_accuracy: 0.6931\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5710 - accuracy: 0.7037 - val_loss: 0.5819 - val_accuracy: 0.7085\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 2s 9ms/step - loss: 0.5656 - accuracy: 0.7115 - val_loss: 0.5841 - val_accuracy: 0.6847\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5673 - accuracy: 0.7064 - val_loss: 0.5738 - val_accuracy: 0.7070\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5644 - accuracy: 0.7101 - val_loss: 0.5768 - val_accuracy: 0.7085\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 1s 6ms/step - loss: 0.5618 - accuracy: 0.7137 - val_loss: 0.5725 - val_accuracy: 0.7209\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.5612 - accuracy: 0.7161 - val_loss: 0.5674 - val_accuracy: 0.7164\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5592 - accuracy: 0.7173 - val_loss: 0.5679 - val_accuracy: 0.7134\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 2s 9ms/step - loss: 0.5546 - accuracy: 0.7171 - val_loss: 0.5679 - val_accuracy: 0.7105\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 3s 14ms/step - loss: 0.5513 - accuracy: 0.7217 - val_loss: 0.5683 - val_accuracy: 0.7139\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5504 - accuracy: 0.7188 - val_loss: 0.5642 - val_accuracy: 0.7214\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 2s 8ms/step - loss: 0.5485 - accuracy: 0.7222 - val_loss: 0.5582 - val_accuracy: 0.7224\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 2s 9ms/step - loss: 0.5465 - accuracy: 0.7250 - val_loss: 0.5768 - val_accuracy: 0.7050\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 3s 10ms/step - loss: 0.5481 - accuracy: 0.7238 - val_loss: 0.5686 - val_accuracy: 0.7164\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5447 - accuracy: 0.7295 - val_loss: 0.5536 - val_accuracy: 0.7318\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5451 - accuracy: 0.7291 - val_loss: 0.5610 - val_accuracy: 0.7263\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5418 - accuracy: 0.7269 - val_loss: 0.5587 - val_accuracy: 0.7353\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 2s 9ms/step - loss: 0.5441 - accuracy: 0.7229 - val_loss: 0.5586 - val_accuracy: 0.7234\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5424 - accuracy: 0.7286 - val_loss: 0.5539 - val_accuracy: 0.7229\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 2s 8ms/step - loss: 0.5399 - accuracy: 0.7299 - val_loss: 0.5689 - val_accuracy: 0.7050\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5394 - accuracy: 0.7348 - val_loss: 0.5731 - val_accuracy: 0.6996\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5407 - accuracy: 0.7307 - val_loss: 0.5528 - val_accuracy: 0.7298\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5383 - accuracy: 0.7348 - val_loss: 0.5609 - val_accuracy: 0.7229\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5370 - accuracy: 0.7343 - val_loss: 0.5747 - val_accuracy: 0.6996\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.5380 - accuracy: 0.7287 - val_loss: 0.5561 - val_accuracy: 0.7258\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 3s 12ms/step - loss: 0.5329 - accuracy: 0.7369 - val_loss: 0.5619 - val_accuracy: 0.7224\n",
      "Epoch 43/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5318 - accuracy: 0.7343 - val_loss: 0.5746 - val_accuracy: 0.7159\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.5349 - accuracy: 0.7315 - val_loss: 0.5661 - val_accuracy: 0.7189\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5337 - accuracy: 0.7370 - val_loss: 0.5437 - val_accuracy: 0.7382\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.5289 - accuracy: 0.7396 - val_loss: 0.5426 - val_accuracy: 0.7397\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.5298 - accuracy: 0.7378 - val_loss: 0.5702 - val_accuracy: 0.6976\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.5326 - accuracy: 0.7342 - val_loss: 0.5443 - val_accuracy: 0.7372\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7396 - val_loss: 0.5452 - val_accuracy: 0.7323\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.5264 - accuracy: 0.7396 - val_loss: 0.5503 - val_accuracy: 0.7348\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.5247 - accuracy: 0.7447 - val_loss: 0.5458 - val_accuracy: 0.7367\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5243 - accuracy: 0.7439 - val_loss: 0.5628 - val_accuracy: 0.7110\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.5286 - accuracy: 0.7389 - val_loss: 0.5462 - val_accuracy: 0.7328\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 1s 6ms/step - loss: 0.5262 - accuracy: 0.7406 - val_loss: 0.5436 - val_accuracy: 0.7298\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 1s 6ms/step - loss: 0.5222 - accuracy: 0.7413 - val_loss: 0.5476 - val_accuracy: 0.7323\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 1s 6ms/step - loss: 0.5237 - accuracy: 0.7437 - val_loss: 0.5491 - val_accuracy: 0.7293\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5209 - accuracy: 0.7446 - val_loss: 0.5515 - val_accuracy: 0.7338\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.5195 - accuracy: 0.7444 - val_loss: 0.5422 - val_accuracy: 0.7447\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5205 - accuracy: 0.7452 - val_loss: 0.5450 - val_accuracy: 0.7343\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.5222 - accuracy: 0.7421 - val_loss: 0.5401 - val_accuracy: 0.7452\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 2s 8ms/step - loss: 0.5157 - accuracy: 0.7451 - val_loss: 0.5334 - val_accuracy: 0.7432\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5202 - accuracy: 0.7461 - val_loss: 0.5361 - val_accuracy: 0.7412\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5173 - accuracy: 0.7460 - val_loss: 0.5455 - val_accuracy: 0.7288\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5165 - accuracy: 0.7485 - val_loss: 0.5350 - val_accuracy: 0.7382\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.5166 - accuracy: 0.7465 - val_loss: 0.5357 - val_accuracy: 0.7471\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5127 - accuracy: 0.7497 - val_loss: 0.5288 - val_accuracy: 0.7462\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.5141 - accuracy: 0.7467 - val_loss: 0.5289 - val_accuracy: 0.7402\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.5117 - accuracy: 0.7488 - val_loss: 0.5290 - val_accuracy: 0.7367\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5111 - accuracy: 0.7478 - val_loss: 0.5312 - val_accuracy: 0.7467\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.5088 - accuracy: 0.7483 - val_loss: 0.5393 - val_accuracy: 0.7308\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.5102 - accuracy: 0.7524 - val_loss: 0.5326 - val_accuracy: 0.7506\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5096 - accuracy: 0.7473 - val_loss: 0.5315 - val_accuracy: 0.7467\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.5098 - accuracy: 0.7494 - val_loss: 0.5433 - val_accuracy: 0.7387\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5072 - accuracy: 0.7528 - val_loss: 0.5433 - val_accuracy: 0.7417\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.5078 - accuracy: 0.7513 - val_loss: 0.5375 - val_accuracy: 0.7338\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5084 - accuracy: 0.7522 - val_loss: 0.5240 - val_accuracy: 0.7501\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5060 - accuracy: 0.7519 - val_loss: 0.5256 - val_accuracy: 0.7457\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5064 - accuracy: 0.7515 - val_loss: 0.5277 - val_accuracy: 0.7486\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.5040 - accuracy: 0.7556 - val_loss: 0.5281 - val_accuracy: 0.7422\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5038 - accuracy: 0.7551 - val_loss: 0.5287 - val_accuracy: 0.7481\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.5048 - accuracy: 0.7540 - val_loss: 0.5586 - val_accuracy: 0.7149\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5044 - accuracy: 0.7540 - val_loss: 0.5215 - val_accuracy: 0.7476\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5041 - accuracy: 0.7530 - val_loss: 0.5259 - val_accuracy: 0.7486\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.5040 - accuracy: 0.7550 - val_loss: 0.5348 - val_accuracy: 0.7333\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5039 - accuracy: 0.7534 - val_loss: 0.5262 - val_accuracy: 0.7491\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5000 - accuracy: 0.7590 - val_loss: 0.5274 - val_accuracy: 0.7382\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5025 - accuracy: 0.7550 - val_loss: 0.5285 - val_accuracy: 0.7516\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5029 - accuracy: 0.7577 - val_loss: 0.5160 - val_accuracy: 0.7576\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5006 - accuracy: 0.7571 - val_loss: 0.5395 - val_accuracy: 0.7422\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4997 - accuracy: 0.7555 - val_loss: 0.5429 - val_accuracy: 0.7348\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 1s 5ms/step - loss: 0.5000 - accuracy: 0.7582 - val_loss: 0.5180 - val_accuracy: 0.7521\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.5017 - accuracy: 0.7556 - val_loss: 0.5196 - val_accuracy: 0.7496\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 1s 6ms/step - loss: 0.4970 - accuracy: 0.7630 - val_loss: 0.5245 - val_accuracy: 0.7501\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4951 - accuracy: 0.7608 - val_loss: 0.5243 - val_accuracy: 0.7551\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 1s 4ms/step - loss: 0.4967 - accuracy: 0.7585 - val_loss: 0.5215 - val_accuracy: 0.7407\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.4957 - accuracy: 0.7585 - val_loss: 0.5273 - val_accuracy: 0.7476\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.4950 - accuracy: 0.7601 - val_loss: 0.5198 - val_accuracy: 0.7516\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 3s 11ms/step - loss: 0.4938 - accuracy: 0.7580 - val_loss: 0.5260 - val_accuracy: 0.7392\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.4921 - accuracy: 0.7654 - val_loss: 0.5258 - val_accuracy: 0.7491\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.4919 - accuracy: 0.7613 - val_loss: 0.5148 - val_accuracy: 0.7556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x241f59ff7c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=32,validation_split=0.2,shuffle=True,verbose=1) # Fit the model on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5029547810554504, 0.7493058443069458]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test) # Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(50.722222222222214, 0.5, 'Truth')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "ypred = model.predict(x_test) # Predict on the test set\n",
    "ypred=ypred>0.5\n",
    "cm = tf.math.confusion_matrix(labels=y_test, predictions=ypred) # Create a confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d') # Plot the confusion matrix\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      1498\n",
      "           1       0.70      0.66      0.68      1023\n",
      "\n",
      "    accuracy                           0.75      2521\n",
      "   macro avg       0.74      0.74      0.74      2521\n",
      "weighted avg       0.75      0.75      0.75      2521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, ypred)) # Print the classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_values):\n",
    "    input_values = input_values[1:]\n",
    "    input_values = input_values.reshape(1, 13)\n",
    "    input_values = np.log1p(input_values)\n",
    "    return input_values\n",
    "\n",
    "def predict(input_values):\n",
    "    input_values = preprocess(input_values)\n",
    "    predicted_class = model.predict(input_values)\n",
    "    predicted_class_label = (predicted_class > 0.5).astype(int)\n",
    "    return predicted_class_label[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORIGINAL IMAGES TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 233ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(predict(np.array([4,2.0,0.8240057548868313,2.9664955,0.7799896569515071,0.0,0.0,0.007766019997521102,0.041094354777394385,\n",
    "                         124.25885484434258,0.9988637884684111,0.0003284650565900022,1.9826796276446994,13.69397433992708])))\n",
    "\n",
    "print(predict(np.array([3,0.0,0.12355278862847222,0.21174723,0.794285697898781,0.0,0.0,0.003242956105418036,0.02529559787990038,\n",
    "                            124.74137108098446,0.9997222873305929,0.00021156162951863116,0.6057347602017548,9.366665678244317])))\n",
    "\n",
    "print(predict(np.array([2,13.0,0.40969780815972223,13.3263645,2.1003133537489274,0.0,0.0,0.01605091790007938,0.002244155750626534,\n",
    "                            134.13091820278453,0.9964026139987351,0.00012864835342581604,7.161383544412562,8.146674663672457])))\n",
    "\n",
    "print(predict(np.array([1,0.0,0.4768812391493056,0.47688124,0.2029589611322936,0.0,0.0,0.0076054001592451665,\n",
    "                            0.015541669419809606,120.96358049513205,0.9994608029123961,0.00028900960949369565,0.7381710210308509,\n",
    "                            13.204835045049549])))\n",
    "\n",
    "print(predict(np.array([0,0.0, 0.7894978841145833, 0.9651923, 0.28709132642652957, 255.0,\n",
    "                            1.1351006245246926e-16, 0.007155012141966531, 0.012494405041388438,\n",
    "                            130.49033500987207, 0.9995915143002699, 0.0003406328222350662,  \n",
    "                            0.9823919214296488, 13.383065745350905])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORIGINAL_IMAGE_TEST-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"dataset_original_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "data1=df1.to_numpy()\n",
    "data1=data1[1:]\n",
    "\n",
    "original_class=[]\n",
    "\n",
    "for row in data1:\n",
    "    row=np.array(row)\n",
    "    predicted_class = predict(row)\n",
    "    original_class.append(predicted_class)\n",
    "\n",
    "print(original_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "print(original_class.count(1))\n",
    "print(original_class.count(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAMPERED_IMAGE_TEST-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv(\"dataset_tampered_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "[0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "data2=df2.to_numpy()\n",
    "data2=data2[1:]\n",
    "\n",
    "tampered_class=[]\n",
    "\n",
    "for row in data2:\n",
    "    row=np.array(row)\n",
    "    predicted_class = predict(row)\n",
    "    tampered_class.append(predicted_class)\n",
    "\n",
    "\n",
    "print(tampered_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "print(tampered_class.count(1))\n",
    "print(tampered_class.count(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
